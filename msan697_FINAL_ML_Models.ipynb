{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-36-222.us-west-2.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_data = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://ec2-34-212-28-18.us-west-2.compute.amazonaws.com/msan697.review\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|                 _id|         business_id|cool|      date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|[5a5d41a969b675a5...|uYHaNptLzDLoV_JZ_...|   0|2016-07-12|    0|VfBHSwC5Vz_pbFluy...|    5|My girlfriend and...|     0|cjpdDjZyprfyDG3Rl...|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_data.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check distribution of the rating star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|    1| 639849|\n",
      "|    3| 570819|\n",
      "|    5|1988003|\n",
      "|    4|1135830|\n",
      "|    2| 402396|\n",
      "+-----+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print review_data.groupBy(review_data[\"stars\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude neutral review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_neg(star):\n",
    "    if star <3:\n",
    "        return int(0) #negative\n",
    "    elif star >3 :\n",
    "        return int(1) #positive\n",
    "    else:\n",
    "        return int(2) #neutral\n",
    "    \n",
    "star_to_senti = udf(lambda x:pos_neg(x))\n",
    "train_test_DF_raw = review_data.select('text',star_to_senti('stars').alias('label')).filter(\"label != 2\") #exclude neutral reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "train_test_DF = train_test_DF_raw.withColumn(\"label\", train_test_DF_raw[\"label\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  0.0|1042245|\n",
      "|  1.0|3123833|\n",
      "+-----+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print train_test_DF.groupBy(train_test_DF[\"label\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|My girlfriend and...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_DF.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|My girlfriend and I stayed here for nights and loved it The location of this hotel and very decent price makes this an amazing deal When you walk out the front door Scott Monument and Princes street are right in front of you Edinburgh Castle and the Royal Mile is a minute walk via a close right around the corner and there are so many hidden gems nearby including Calton Hill and the newly opened Arches that made this location incredible The hotel itself was also very nice with a reasonably priced bar very considerate staff and small but comfortable rooms with excellent bathrooms and showers Only two minor complaints are no telephones in room for room service not a huge deal for us and no AC in the room but they have huge windows which can be fully opened The staff were incredible though letting us borrow umbrellas for the rain giving us maps and directions and also when we had lost our only UK adapter for charging our phones gave us a very fancy one for free I would highly recommend this hotel to friends and when I return to Edinburgh which I most definitely will I will be staying here without any hesitation|1.0  |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove punctuation\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_num_punct(text):\n",
    "\n",
    "    my_string = text.replace(\"-\", \" \")\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", my_string)  # delete stuff but leave at least a space to avoid clumping together\n",
    "\n",
    "    nopunct = nopunct.split()\n",
    "    #nopunct = [stemmer.stem(w).strip(\" \") for w in nopunct] #remove stop word and normalize word using stemmer.\n",
    "    nopunct = [w.strip() for w in nopunct]\n",
    "    nopunct = ' '.join(nopunct)\n",
    "    \n",
    "    return nopunct\n",
    "\n",
    "udf_num_punct = udf(lambda x:remove_num_punct(x))\n",
    "review_rmsw = train_test_DF.select(udf_num_punct('text').alias('text'), 'label')\n",
    "review_rmsw.show(1,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### setNumFeatures(20)\n",
    "n_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "hashingTF = HashingTF().setNumFeatures(n_features).setInputCol(\"filtered\").setOutputCol(\"rawFeatures\")\n",
    "idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set= review_rmsw.randomSplit([0.8, 0.2])\n",
    "train_set = train_set.cache()\n",
    "test_set = test_set.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute accuracy on the test set \n",
    "def evaluate_metric(predictions):\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")\n",
    "    print \"Area under ROC curve:\",evaluator.evaluate(predictions)\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    print(\"F1_score = %0.4f\" %(f1))\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy = %0.4f\" %(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.90763606097\n",
      "F1_score = 0.8299\n",
      "Accuracy = 0.8466\n",
      "CPU times: user 576 ms, sys: 184 ms, total: 760 ms\n",
      "Wall time: 19min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr =  LogisticRegression(maxIter=100, regParam=0.01, elasticNetParam=0.8)\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, lr])\n",
    "logreg_model=pipeline.fit(train_set)\n",
    "predictions = logreg_model.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|[-1.5326953530699...|[0.17759966568357...|       1.0|\n",
      "|A bit of good and...|  1.0|[a, bit, of, good...|[bit, good, bad, ...|(1000,[1,7,17,20,...|(1000,[1,7,17,20,...|[-2.4657070055305...|[0.07829748728691...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|(1000,[19,43,144,...|(1000,[19,43,144,...|[-2.0775574794838...|[0.11129732771211...|       1.0|\n",
      "|A few years ago i...|  1.0|[a, few, years, a...|[years, ago, aske...|(1000,[3,14,29,77...|(1000,[3,14,29,77...|[-3.8033548543428...|[0.02180958378484...|       1.0|\n",
      "|A friend and I di...|  1.0|[a, friend, and, ...|[friend, discover...|(1000,[13,17,29,4...|(1000,[13,17,29,4...|[-0.6471211857084...|[0.34363856446248...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Unigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.611796077574\n",
      "F1_score = 0.8502\n",
      "Accuracy = 0.8480\n",
      "CPU times: user 168 ms, sys: 24 ms, total: 192 ms\n",
      "Wall time: 11min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, nb])\n",
    "nb_model=pipeline.fit(train_set)\n",
    "nb_prediction = nb_model.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|[-157.87430553725...|[0.00344249451876...|       1.0|\n",
      "|A bit of good and...|  1.0|[a, bit, of, good...|[bit, good, bad, ...|(1000,[1,7,17,20,...|(1000,[1,7,17,20,...|[-2560.0339187730...|[1.83722486379919...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|(1000,[19,43,144,...|(1000,[19,43,144,...|[-878.77050411191...|[4.81488550846858...|       1.0|\n",
      "|A few years ago i...|  1.0|[a, few, years, a...|[years, ago, aske...|(1000,[3,14,29,77...|(1000,[3,14,29,77...|[-612.90077331084...|[2.05811441170098...|       1.0|\n",
      "|A friend and I di...|  1.0|[a, friend, and, ...|[friend, discover...|(1000,[13,17,29,4...|(1000,[13,17,29,4...|[-1484.5920768138...|[0.90151844237117...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "#remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "bigram = NGram(n=2, inputCol=\"filtered\", outputCol=\"bigrams\")\n",
    "hashingTF_bigram = HashingTF().setNumFeatures(n_features).setInputCol(\"bigrams\").setOutputCol(\"rawFeatures\")\n",
    "idf_bigram = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.606786650712\n",
      "F1_score = 0.7330\n",
      "Accuracy = 0.7366\n",
      "CPU times: user 252 ms, sys: 16 ms, total: 268 ms\n",
      "Wall time: 23min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,bigram,hashingTF_bigram,idf_bigram, nb])\n",
    "nb_model_bigram=pipeline.fit(train_set)\n",
    "nb_prediction_bigram = nb_model_bigram.transform(test_set)\n",
    "\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|             bigrams|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|[double double, d...|(1000,[37,120,197...|(1000,[37,120,197...|[-146.40989752116...|[0.25797807881001...|       1.0|\n",
      "|A float plane in ...|  1.0|[a, float, plane,...|[float, plane, de...|[float plane, pla...|(1000,[6,15,17,19...|(1000,[6,15,17,19...|[-1325.2931946499...|[0.78921656227107...|       0.0|\n",
      "|A nice ambiance r...|  1.0|[a, nice, ambianc...|[nice, ambiance, ...|[nice ambiance, a...|(1000,[59,178,245...|(1000,[59,178,245...|[-443.42660107534...|[0.42692544108826...|       1.0|\n",
      "|A short walk nort...|  1.0|[a, short, walk, ...|[short, walk, nor...|[short walk, walk...|(1000,[49,62,83,1...|(1000,[49,62,83,1...|[-2423.5810640471...|[0.01524124988761...|       1.0|\n",
      "|AMAZING Went at t...|  1.0|[amazing, went, a...|[amazing, went, t...|[amazing went, we...|(1000,[42,61,67,7...|(1000,[42,61,67,7...|[-702.78567610289...|[0.11022741410834...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_bigram.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Trigram Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tribgram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "#remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "trigram = NGram(n=3, inputCol=\"filtered\", outputCol=\"trigrams\")\n",
    "hashingTF_trigram = HashingTF().setNumFeatures(n_features).setInputCol(\"trigrams\").setOutputCol(\"rawFeatures\")\n",
    "idf_trigram = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.606786650712\n",
      "F1_score = 0.7330\n",
      "Accuracy = 0.7366\n",
      "CPU times: user 200 ms, sys: 36 ms, total: 236 ms\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,trigram,hashingTF_trigram,idf_trigram, nb])\n",
    "nb_model_trigram=pipeline.fit(train_set)\n",
    "nb_prediction_trigram = nb_model_trigram.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|            trigrams|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|[double double w,...|(1000,[18,134,302...|(1000,[18,134,302...|[-124.25031221642...|[0.27254382101278...|       1.0|\n",
      "|A float plane in ...|  1.0|[a, float, plane,...|[float, plane, de...|[float plane dese...|(1000,[12,13,55,8...|(1000,[12,13,55,8...|[-1309.6464331598...|[0.17839287010797...|       1.0|\n",
      "|A nice ambiance r...|  1.0|[a, nice, ambianc...|[nice, ambiance, ...|[nice ambiance re...|(1000,[95,103,135...|(1000,[95,103,135...|[-431.66043605834...|[0.28036466032346...|       1.0|\n",
      "|A short walk nort...|  1.0|[a, short, walk, ...|[short, walk, nor...|[short walk north...|(1000,[10,16,18,4...|(1000,[10,16,18,4...|[-2397.5736317405...|[0.28604855995628...|       1.0|\n",
      "|AMAZING Went at t...|  1.0|[amazing, went, a...|[amazing, went, t...|[amazing went tea...|(1000,[21,28,84,9...|(1000,[21,28,84,9...|[-676.27546519392...|[0.28182266384975...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_trigram.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model 5: Multilayer perceptron classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 20 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "\n",
    "# %%time\n",
    "\n",
    "layers = [n_features, 5 , 2] \n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, trainer])\n",
    "nn_model = pipeline.fit(train_set)\n",
    "\n",
    "nn_prediction = nn_model.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|       1.0|\n",
      "|A float plane in ...|  1.0|[a, float, plane,...|[float, plane, de...|(1000,[3,42,51,69...|(1000,[3,42,51,69...|       1.0|\n",
      "|A nice ambiance r...|  1.0|[a, nice, ambianc...|[nice, ambiance, ...|(1000,[44,73,92,1...|(1000,[44,73,92,1...|       1.0|\n",
      "|A short walk nort...|  1.0|[a, short, walk, ...|[short, walk, nor...|(1000,[8,25,44,77...|(1000,[8,25,44,77...|       1.0|\n",
      "|AMAZING Went at t...|  1.0|[amazing, went, a...|[amazing, went, t...|(1000,[1,36,62,76...|(1000,[1,36,62,76...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.8898\n"
     ]
    }
   ],
   "source": [
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(nn_prediction)\n",
    "    print(\"F1_score = %0.4f\" %(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8914\n"
     ]
    }
   ],
   "source": [
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(nn_prediction)\n",
    "    print(\"Accuracy = %0.4f\" %(accuracy))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
